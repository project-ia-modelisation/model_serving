import pickle
import numpy as np
import trimesh
import os

def load_preprocessed_model(filepath):
    """ Charger un mod√®le 3D pr√©trait√© depuis un fichier pickle. """
    try:
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"Le fichier sp√©cifi√© n'existe pas : {filepath}")
        
        with open(filepath, 'rb') as f:
            model = pickle.load(f)

        # Si le mod√®le est un TrackedArray, le convertir en Trimesh
        if isinstance(model, np.ndarray):
            model = trimesh.Trimesh(vertices=model)
        elif isinstance(model, trimesh.caching.TrackedArray):
            model = trimesh.Trimesh(vertices=model.data)

        if not isinstance(model, trimesh.Trimesh):
            raise ValueError(f"Le fichier pickle ne contient pas un objet Trimesh valide. Type d√©tect√© : {type(model)}.")

        if len(model.vertices) == 0:
            raise ValueError("Le mod√®le pr√©trait√© est vide. Aucun sommet n'a √©t√© trouv√©.")

        print(f"‚úÖ Mod√®le pr√©trait√© charg√© avec succ√®s : {type(model)} avec {len(model.vertices)} sommets.")
        return model
    except FileNotFoundError as fnf_error:
        print(f"‚ùå Erreur : {fnf_error}")
        return None
    except pickle.UnpicklingError:
        print("‚ùå Erreur lors du d√©pickle du fichier. Il pourrait √™tre corrompu.")
        return None
    except ValueError as val_error:
        print(f"‚ùå Erreur de validation : {val_error}")
        return None
    except Exception as e:
        print(f"‚ùå Erreur inattendue lors du chargement du mod√®le pr√©trait√© : {e}")
        return None


def resample_vertices(vertices, target_count, model_name="Mod√®le inconnu"):
    """
    R√©√©chantillonne un ensemble de sommets pour atteindre un nombre cible de points.
    """
    print(f"üîÑ [resample_vertices] {model_name} : {len(vertices)} ‚Üí Cible : {target_count}")

    if len(vertices) == 0:
        raise ValueError("‚ùå ERREUR : Les sommets d'entr√©e sont vides.")

    try:
        mesh = trimesh.Trimesh(vertices=vertices)
        if len(vertices) < target_count:
            points_to_add = target_count - len(vertices)

            if len(mesh.faces) == 0:
                raise ValueError("‚ö†Ô∏è Pas de faces, interpolation lin√©aire forc√©e...")

            new_points, _ = trimesh.sample.sample_surface_even(mesh, points_to_add)
            if new_points is None or len(new_points) == 0:
                raise ValueError("‚ùå ERREUR CRITIQUE : `sample_surface_even()` a retourn√© un tableau vide !")

            resampled = np.vstack((vertices, new_points))
        else:
            indices = np.linspace(0, len(vertices) - 1, target_count, dtype=int)
            resampled = vertices[indices]
    except Exception as e:
        print(f"‚ö†Ô∏è [resample_vertices] {e}")
        print("üõë Passage en mode interpolation lin√©aire...")
        new_points = np.tile(vertices, (target_count // len(vertices) + 1, 1))[:target_count]
        resampled = new_points

    resampled = resampled[:target_count]  # üîí S'assure qu'on a exactement target_count sommets
    print(f"üìä [resample_vertices] {model_name} apr√®s r√©√©chantillonnage : {len(resampled)} sommets")
    return resampled

def validate_faces(model):
    """ V√©rifie que les indices des faces ne d√©passent pas la taille des sommets. """
    if not isinstance(model, trimesh.Trimesh):
        raise ValueError("L'objet fourni n'est pas un mod√®le Trimesh valide.")

    if len(model.faces) == 0:
        raise ValueError("Le mod√®le ne contient aucune face.")

    max_index = len(model.vertices) - 1
    for i, face in enumerate(model.faces):
        if any(index > max_index or index < 0 for index in face):
            raise ValueError(f"‚ùå Indice de face invalide d√©tect√© √† la face {i} : {face}")

    print("‚úÖ V√©rification des indices des faces termin√©e, aucun probl√®me d√©tect√©.")

def evaluate_model(preprocessed_model, ground_truth_model):
    """
    √âvalue la similarit√© entre le mod√®le pr√©trait√© et le mod√®le de v√©rit√© terrain.
    """
    try:
        if not isinstance(preprocessed_model, trimesh.Trimesh):
            raise ValueError(f"‚ùå ERREUR : preprocessed_model n'est pas un Trimesh mais {type(preprocessed_model)}")
        if not isinstance(ground_truth_model, trimesh.Trimesh):
            raise ValueError(f"‚ùå ERREUR : ground_truth_model n'est pas un Trimesh mais {type(ground_truth_model)}")

        # V√©rification des tailles avant r√©√©chantillonnage
        print(f"üîç V√©rification des tailles avant r√©√©chantillonnage...")
        print(f"   üîπ Pr√©dits : {len(preprocessed_model.vertices)} sommets")
        print(f"   üîπ V√©rit√© terrain : {len(ground_truth_model.vertices)} sommets")

        target_count = max(len(preprocessed_model.vertices), len(ground_truth_model.vertices))
        preprocessed_resampled = resample_vertices(preprocessed_model.vertices, target_count, "Mod√®le pr√©trait√©")
        ground_truth_resampled = resample_vertices(ground_truth_model.vertices, target_count, "Mod√®le v√©rit√© terrain")

        print("‚úÖ R√©√©chantillonnage termin√© :", len(preprocessed_resampled), "sommets align√©s")

        # Calculer la similarit√© entre les mod√®les r√©√©chantillonn√©s
        # Ajoutez votre logique d'√©valuation ici

        return {"similarity_score": 0.9}  # Exemple de score de similarit√©
    
    except Exception as e:
        print(f"‚ùå Erreur lors de l'√©valuation du mod√®le : {e}")
        return None

def compute_metrics(predicted_vertices, ground_truth_vertices):
    """ Calcul des m√©triques entre sommets pr√©dit et v√©rit√© terrain. """
    if not isinstance(predicted_vertices, np.ndarray) or not isinstance(ground_truth_vertices, np.ndarray):
        raise ValueError("‚ùå ERREUR : Les sommets doivent √™tre des tableaux numpy.")

    if predicted_vertices.shape != ground_truth_vertices.shape:
        raise ValueError("‚ùå ERREUR : Les sommets doivent avoir la m√™me forme apr√®s r√©√©chantillonnage.")

    metrics = {
        "mean_squared_error": float(np.mean((predicted_vertices - ground_truth_vertices) ** 2)),
        "max_error": float(np.max(np.abs(predicted_vertices - ground_truth_vertices))),
        "average_distance": float(np.mean(np.linalg.norm(predicted_vertices - ground_truth_vertices, axis=1)))
    }
    return metrics
