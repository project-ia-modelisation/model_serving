import pickle
import numpy as np
import trimesh

def load_preprocessed_model(filepath):
    """ Charger un mod√®le 3D pr√©trait√© depuis un fichier pickle. """
    try:
        with open(filepath, 'rb') as f:
            model = pickle.load(f)
        
        if not isinstance(model, trimesh.Trimesh):
            raise ValueError("Le fichier pickle ne contient pas un objet Trimesh valide.")

        if len(model.vertices) == 0:
            raise ValueError("Le mod√®le pr√©trait√© est vide.")

        print(f"‚úÖ Mod√®le pr√©trait√© charg√© : {type(model)} avec {len(model.vertices)} sommets.")
        return model
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le pr√©trait√© : {e}")
        return None

def resample_vertices(vertices, target_count, model_name="Mod√®le inconnu"):
    """
    R√©√©chantillonne un ensemble de sommets pour atteindre un nombre cible de points.
    """
    print(f"üîÑ [resample_vertices] {model_name} : {len(vertices)} ‚Üí Cible : {target_count}")

    if len(vertices) == 0:
        raise ValueError("‚ùå ERREUR : Les sommets d'entr√©e sont vides.")
    
    try:
        mesh = trimesh.Trimesh(vertices=vertices)
        if len(vertices) < target_count:
            points_to_add = target_count - len(vertices)
            
            if len(mesh.faces) == 0:
                raise ValueError("‚ö†Ô∏è Pas de faces, interpolation lin√©aire forc√©e...")
            
            new_points, _ = trimesh.sample.sample_surface_even(mesh, points_to_add)
            if new_points is None or len(new_points) == 0:
                raise ValueError("‚ùå ERREUR CRITIQUE : `sample_surface_even()` a retourn√© un tableau vide !")
            
            resampled = np.vstack((vertices, new_points))
        else:
            indices = np.linspace(0, len(vertices) - 1, target_count, dtype=int)
            resampled = vertices[indices]
    except Exception as e:
        print(f"‚ö†Ô∏è [resample_vertices] {e}")
        print("üõë Passage en mode interpolation lin√©aire...")
        new_points = np.tile(vertices, (target_count // len(vertices) + 1, 1))[:target_count]
        resampled = new_points

    print(f"üìä [resample_vertices] {model_name} apr√®s r√©√©chantillonnage : {len(resampled)} sommets")
    return resampled

def validate_faces(model):
    """ V√©rifie que les indices des faces ne d√©passent pas la taille des sommets. """
    if not isinstance(model, trimesh.Trimesh):
        raise ValueError("L'objet fourni n'est pas un mod√®le Trimesh valide.")
    
    if len(model.faces) == 0:
        raise ValueError("Le mod√®le ne contient aucune face.")

    max_index = len(model.vertices) - 1
    for i, face in enumerate(model.faces):
        if any(index > max_index or index < 0 for index in face):
            raise ValueError(f"‚ùå Indice de face invalide d√©tect√© √† la face {i} : {face}")

    print("‚úÖ V√©rification des indices des faces termin√©e, aucun probl√®me d√©tect√©.")

def evaluate_model(preprocessed_model, ground_truth_model):
    """
    √âvalue la similarit√© entre le mod√®le pr√©trait√© et le mod√®le de v√©rit√© terrain.
    """
    try:
        # V√©rification des mod√®les
        if not isinstance(preprocessed_model, trimesh.Trimesh):
            raise ValueError(f"‚ùå ERREUR : preprocessed_model n'est pas un Trimesh mais {type(preprocessed_model)}")
        if not isinstance(ground_truth_model, trimesh.Trimesh):
            raise ValueError(f"‚ùå ERREUR : ground_truth_model n'est pas un Trimesh mais {type(ground_truth_model)}")

        # V√©rification des tailles
        print("üîç V√©rification des tailles avant r√©√©chantillonnage...")
        print(f"   üîπ Pr√©dits : {len(preprocessed_model.vertices)} sommets")
        print(f"   üîπ V√©rit√© terrain : {len(ground_truth_model.vertices)} sommets")

        # R√©√©chantillonnage
        target_count = max(len(preprocessed_model.vertices), len(ground_truth_model.vertices))
        preprocessed_resampled = resample_vertices(preprocessed_model.vertices, target_count, "Mod√®le pr√©trait√©")
        ground_truth_resampled = resample_vertices(ground_truth_model.vertices, target_count, "Mod√®le v√©rit√© terrain")

        # V√©rification apr√®s r√©√©chantillonnage
        print("‚úÖ R√©√©chantillonnage termin√© :", len(preprocessed_resampled), "sommets align√©s")
        
        # Cr√©ation de nouveaux objets Trimesh apr√®s r√©√©chantillonnage
        preprocessed_model = trimesh.Trimesh(vertices=preprocessed_resampled, faces=preprocessed_model.faces)
        ground_truth_model = trimesh.Trimesh(vertices=ground_truth_resampled, faces=ground_truth_model.faces)

        # V√©rifier que la conversion a bien fonctionn√©
        if not isinstance(preprocessed_model, trimesh.Trimesh):
            raise ValueError("‚ùå ERREUR : Conversion du mod√®le pr√©trait√© en Trimesh √©chou√©e !")
        if not isinstance(ground_truth_model, trimesh.Trimesh):
            raise ValueError("‚ùå ERREUR : Conversion du mod√®le v√©rit√© terrain en Trimesh √©chou√©e !")

        # V√©rification des indices des faces
        validate_faces(ground_truth_model)

        # Calcul des m√©triques
        metrics = compute_metrics(preprocessed_model.vertices, ground_truth_model.vertices)
        print("üìä R√©sultats des m√©triques :", metrics)
        return metrics
    
    except ValueError as ve:
        print(f"üö® Erreur de validation lors de l'√©valuation : {str(ve)}")
        return None
    except Exception as e:
        print(f"üõë Erreur inattendue lors de l'√©valuation : {str(e)}")
        return None

def compute_metrics(predicted_vertices, ground_truth_vertices):
    """ Calcul des m√©triques entre sommets pr√©dit et v√©rit√© terrain. """
    if not isinstance(predicted_vertices, np.ndarray) or not isinstance(ground_truth_vertices, np.ndarray):
        raise ValueError("‚ùå ERREUR : Les sommets doivent √™tre des tableaux numpy.")
    
    if predicted_vertices.shape != ground_truth_vertices.shape:
        raise ValueError("‚ùå ERREUR : Les sommets doivent avoir la m√™me forme apr√®s r√©√©chantillonnage.")
    
    metrics = {
        "mean_squared_error": float(np.mean((predicted_vertices - ground_truth_vertices) ** 2)),
        "max_error": float(np.max(np.abs(predicted_vertices - ground_truth_vertices))),
        "average_distance": float(np.mean(np.linalg.norm(predicted_vertices - ground_truth_vertices, axis=1)))
    }
    return metrics